{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e991a08b",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7816c770",
   "metadata": {},
   "source": [
    "### [opencv](https://docs.opencv.org/4.x/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9459f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install OpenCV\n",
    "\n",
    "pip install opencv3\n",
    "\n",
    "# in terminal\n",
    "# or conda install opencv3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d09842b",
   "metadata": {},
   "source": [
    "### [keras](https://keras.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cfb36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the above installation command did not work for your computer, try accessing opencv3 through a specific source\n",
    "\n",
    "pip install keras\n",
    "\n",
    "# or\n",
    "\n",
    "# in terminal\n",
    "# conda install -c conda-forge opencv=3.2.0 \n",
    "\n",
    "# conda install -c menpo opencv3=3.2.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f717f37",
   "metadata": {},
   "source": [
    "### Step 1: import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c8b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb81c977",
   "metadata": {},
   "source": [
    "The blueLower and the blueUpper numpy arrays help us in finding the blue colored cap. The kernal helps in smoothing blue cap once found. The bpoints, gpoints, rpoints and ypoints deques are used to store the points drawn on the screen of color blue, green, red and yellow respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4dc1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the upper and lower boundaries for a color to be considered \"Blue\"\n",
    "blueLower = np.array([100, 60, 60])\n",
    "blueUpper = np.array([140, 255, 255])\n",
    "\n",
    "# Define a 5x5 kernel for erosion and dilation\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Initialize deques to store different colors in different arrays\n",
    "bpoints = [deque(maxlen=512)]\n",
    "gpoints = [deque(maxlen=512)]\n",
    "rpoints = [deque(maxlen=512)]\n",
    "ypoints = [deque(maxlen=512)]\n",
    "\n",
    "# Initialize an index variable for each of the colors \n",
    "bindex = 0\n",
    "gindex = 0\n",
    "rindex = 0\n",
    "yindex = 0\n",
    "\n",
    "# Just a handy array and an index variable to get the color-of-interest on the go\n",
    "# Blue, Green, Red, Yellow respectively\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (0, 255, 255)] \n",
    "colorIndex = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c33c1f",
   "metadata": {},
   "source": [
    "### Step 2: Setup The Paint Interface\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47009990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a blank white image\n",
    "paintWindow = np.zeros((471,636,3)) + 255\n",
    "\n",
    "# Draw buttons like colored rectangles on the white image\n",
    "paintWindow = cv2.rectangle(paintWindow, (40,1), (140,65), (0,0,0), 2)\n",
    "paintWindow = cv2.rectangle(paintWindow, (160,1), (255,65), colors[0], -1)\n",
    "paintWindow = cv2.rectangle(paintWindow, (275,1), (370,65), colors[1], -1)\n",
    "paintWindow = cv2.rectangle(paintWindow, (390,1), (485,65), colors[2], -1)\n",
    "paintWindow = cv2.rectangle(paintWindow, (505,1), (600,65), colors[3], -1)\n",
    "\n",
    "# Label the rectanglular boxes drawn on the image\n",
    "cv2.putText(paintWindow, \"CLEAR ALL\", (49, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "cv2.putText(paintWindow, \"BLUE\", (185, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(paintWindow, \"GREEN\", (298, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(paintWindow, \"RED\", (420, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(paintWindow, \"YELLOW\", (520, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150,150,150), 2, cv2.LINE_AA)\n",
    "\n",
    "# Create a window to display the above image (later)\n",
    "cv2.namedWindow('Paint', cv2.WINDOW_AUTOSIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c1428",
   "metadata": {},
   "source": [
    "### Step 3: Start Reading The Video (Frame by Frame)\n",
    "\n",
    "Use the OpenCV function <strong>cv2.VideoCapture()</strong> method to read a video, frame by frame (using a while loop), either from a video file or from a webcam in real-time. In this case, we pass 0 to the method to read from a webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e57ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "# Keep looping\n",
    "while True:\n",
    "    # Grab the current paintWindow\n",
    "    (grabbed, frame) = camera.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Check to see if we have reached the end of the video (useful when input is a video file not a live video stream)\n",
    "    if not grabbed:\n",
    "        break    \n",
    "    \n",
    "    # Add the same paint interface to the camera feed captured through the webcam (for ease of usage)\n",
    "    frame = cv2.rectangle(frame, (40,1), (140,65), (122,122,122), -1)\n",
    "    frame = cv2.rectangle(frame, (160,1), (255,65), colors[0], -1)\n",
    "    frame = cv2.rectangle(frame, (275,1), (370,65), colors[1], -1)\n",
    "    frame = cv2.rectangle(frame, (390,1), (485,65), colors[2], -1)\n",
    "    frame = cv2.rectangle(frame, (505,1), (600,65), colors[3], -1)\n",
    "    cv2.putText(frame, \"CLEAR ALL\", (49, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame, \"BLUE\", (185, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame, \"GREEN\", (298, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame, \"RED\", (420, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame, \"YELLOW\", (520, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150,150,150), 2, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4528e077",
   "metadata": {},
   "source": [
    "### Step 4: Find The Contour-Of-Interest (The Bottle Cap)\n",
    "\n",
    "Once we start reading the webcam feed, we constantly look for a blue color object in the frames with the help of <strong>cv2.inRange()</strong> method and use the blueUpper and blueLower variables initialized in Step 0. Once we find the contour, we do a series of image operations and make it smooth. They just makes our lives easier. If you want to know more about these operations â€” erode, morph and dilate, check [this](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html) out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bfb0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Determine which pixels fall within the blue boundaries and then blur the binary image\n",
    "    blueMask = cv2.inRange(hsv, blueLower, blueUpper)\n",
    "    blueMask = cv2.erode(blueMask, kernel, iterations=2)\n",
    "    blueMask = cv2.morphologyEx(blueMask, cv2.MORPH_OPEN, kernel)\n",
    "    blueMask = cv2.dilate(blueMask, kernel, iterations=1)\n",
    "\n",
    "    # Find contours in the image\n",
    "    (_, cnts, _) = cv2.findContours(blueMask.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9351cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Check to see if any contours (blue stuff) were found\n",
    "    if len(cnts) > 0:\n",
    "        \n",
    "        # Sort the contours and find the largest one -- we assume this contour correspondes to the area of the bottle cap\n",
    "        cnt = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "        \n",
    "        # Get the radius of the enclosing circle around the found contour\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "        \n",
    "        # Draw the circle around the contour\n",
    "        cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "        \n",
    "        # Get the moments to calculate the center of the contour (in this case a circle)\n",
    "        M = cv2.moments(cnt)\n",
    "        center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64d4b2",
   "metadata": {},
   "source": [
    "The above code finds the contour (the largest one), draws a circle around it using the <strong>cv2.minEnclosingCircle()</strong> and <strong>cv2.circle()</strong> methods, gets the center of the contour found with the help of <strong>cv2.moments()</strong> method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f4101",
   "metadata": {},
   "source": [
    "### Step 5: Start Drawing And Store The Drawings\n",
    "\n",
    "We start tracking coordinates of each and every point the center of the contour touches on the screen, along with its color. We store these set of points of different colors in different deques (bpoints, gpoints etc.). When the center of the contour touches one of the colored boxes we put on the screen in Step 1, we store the points in its respective color deque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Check to see if any contours (blue stuff) were found\n",
    "    if len(cnts) > 0:\n",
    "        \n",
    "        # Sort the contours and find the largest one -- we assume this contour correspondes to the area of the bottle cap\n",
    "        cnt = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "        \n",
    "        # Get the radius of the enclosing circle around the found contour\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "        \n",
    "        # Draw the circle around the contour\n",
    "        cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "        \n",
    "        # Get the moments to calculate the center of the contour (in this case a circle)\n",
    "        M = cv2.moments(cnt)\n",
    "        center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12926ad7",
   "metadata": {},
   "source": [
    "### Step 6: Show The Drawings On The Screen\n",
    "\n",
    "Now we just join them using a line of their own color. The OpenCV function <strong>cv2.line()</strong> comes in handy for us to do that. The following code does the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Draw lines of all the colors (Blue, Green, Red and Yellow)\n",
    "    points = [bpoints, gpoints, rpoints, ypoints]\n",
    "    for i in range(len(points)):\n",
    "        for j in range(len(points[i])):\n",
    "            for k in range(1, len(points[i][j])):\n",
    "                if points[i][j][k - 1] is None or points[i][j][k] is None:\n",
    "                    continue\n",
    "                cv2.line(frame, points[i][j][k - 1], points[i][j][k], colors[i], 2)\n",
    "                cv2.line(paintWindow, points[i][j][k - 1], points[i][j][k], colors[i], 2)\n",
    "\n",
    "    # Show the frame and the paintWindow image\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    cv2.imshow(\"Paint\", paintWindow)\n",
    "\n",
    "    # If the 'q' key is pressed, stop the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f20a97",
   "metadata": {},
   "source": [
    "Once we join all the points in each and every frame with a line and put it on both the windows we created using cv2.imshow() method and it all fits perfectly to work like a paint application. After falling out of the while loop we entered to read data from the webcam, we release the camera and destroy all the windows using the following lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup code\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
